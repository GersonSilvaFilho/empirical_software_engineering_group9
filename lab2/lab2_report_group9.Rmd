---
title: "Empirical software engineering"
subtitle: |
  | Lab 2: ANOVA
  | Group 9
output:
  pdf_document
author:
  - Anton Lutteman
  - Daniel Olsson
  - Gerson Silva Filho
  - Johan Mejborn
date: "`r format(Sys.time(), '%d %B %Y')`"
---
# Exercise 1 - Time to Develop

## a) Minimum amount of users
```{r 1_a}
pwr.anova.test(k = 5, n = NULL, f = 0.08, sig.level = 0.05, power = 0.90)
```

According to the ANOVA test the amount of users in each group is **483** for the
experiment have power 0.9. The minimum amount of monthly users that the company 
must have is 2415, which is 5 (the number of groups) times the amount of users in
each group. 

The effect size is inversely proportional to the number of users needed for the test. 
If we accept a larger effect the number of users needed shrinks, with this
power and significance levels. On the other hand, if we make the effect 
smaller we need a higher number of users to this significance level and power.

## b) Descriptive Statistics
```{r 1_b}
df <- read.csv(file = 'gotaflix-abn.csv',sep = ",")
df$Cover <- as.factor(df$Cover)
df$Engagement <- as.numeric(df$Engagement)

psych::describeBy(df$Engagement,list(df$Cover), mat=T)
```


## c) Linear Model
```{r 1_c}
lm <- lm(Engagement ~ Cover,df)
```

Equation that represents the model:
\begin{equation}
C = 1 -> 0.160367 + 0.017948
\end{equation}

The intercept, in this case, represents the **Cover A**. 

If the the model gives only **Cover C** as 1, it means that it's the reference 
for all the other covers.

## d) Normality
```{r 1_d_1}
car::qqPlot(Engagement ~ Cover,df)
```

With this plots is a bit hard to be sure about the normality, but there are no 
reason to believe the opposite.

```{r 1_d_2}
car::qqPlot(lm$residuals)
```

Also the plot of the residuals look ok, but the data visualization is a bit hard.

```{r 1_d_3}
shapiro.test(df$Engagement)
```

Using the Shapiro Wilk test we can believe that the data follows a normal distribution
sing the W value is 1 and p-value is bigger than alpha.

## e) Scatter plot

```{r 1_e , fig.show="hold", out.width="50%"}
plot(lm)
car::leveneTest(lm)
```

We interpret the null hypothesis of the test as being if the data have homoscedasticity. 
Since the P-value is 0.93, it is larger than alpha and the null hypothesis can't be rejected.


## f) Independence Assumption

There is no test that can run to verify the independence of the data. It's part of 
the design of the experiment and should be handled in the collection phase.

## g) Homoscedasticity analysis modified data

```{r 1_g , fig.show="hold", out.width="50%"}
car::leveneTest(lm2)
```

We interpret the null hypothesis of the test as being if the data have homoscedasticity.
Since the P-value is very small, and much smaller than alpha, the null hypothesis can be rejected
and we can say with confidence that the data **does not have homoscedasticity.**

## h) Which art cover had a better engagement?

```{r 1_h_1}
summary(lm)
car::Anova(lm)
```

The model is statistically significant and we reject the hypothesis that the mean is equal for all groups.

```{r 1_h_2}
tuk <- TukeyHSD(aov(lm))
plot(tuk)
```

We are confident that Cover C is better than A, B and D by looking at the plot of the Tukey test.
However, we can't say with confidence that C is better than E.

# Exercise 2 - Full Factorial Experiment

## a) Experimental Groups

There are four experimental groups assigned to each of the combinations of treatments. The groups consist of the randomly assigned users.

## b) Linear model equation

```{r 2_b_1}
lm(Engagement ~ Cover + Summary, df3)
```
Equation that represents the model:
\begin{equation}
Engagement = 0.169028  - 0.008812 * Cover - 0.006087 * Summary
\end{equation}

```{r 2_b_2}
lm(Engagement ~ Cover*Summary, df3)
```
Equation that represents the model:
\begin{equation}
Engagement = 0.17527 - 0.02129 * Cover - 0.01856  * Summary + (0.02495 * Cover * Summary)
\end{equation}

The intercept, in both cases, is the engagement for factors Cover = Character and Summary = Character


## c) ANOVA assumptions

The samples were taken randomly so the assumption of independence holds.

Test for normality:
```{r 2_c_1}
shapiro.test(df3$Engagement)
```

The Shapiro Wilks test with W=0.999 with a p value of 0.3843, therefore we cannot reject the null hypothesis.

Test for homoscedasticity:
```{r 2_c_2}
car::leveneTest(lm5)
```

The results of the levene test tells us that we can reject the null hypothesis that the data is homoscedastic, however with large sample sizes the test is likely to report small p values for very small deviations from homoscedasticity.

We plot the data to observe the homoscedasticity, also we sampled it in order to get a better visualization.
```{r 2_c_3}
car::qqPlot(sample(lm5$residuals,1000))
```

Our conclusion is that we cannot reject the hypothesis that the data is homoscedastic.

Given the analysis we assume that the assumptions hold.

## d) ANOVA table
```{r 2_d_1, results = "asis"}
stargazer::stargazer(car::Anova(lm5),summary = F, header = F)
```

The conclusion that we draw from the ANOVA table is that the Cover and the Interaction were statistically significant. The effect sizes of each value can be seen in Table 1 F Value column.

```{r 2_d_2, results='hide'}
TukeyHSD(aov(lm5))
```

According to the Tukey test we can say that the Character is better than Genre for Cover to, get a higher engagement. For the interaction, we see that the combination Character - Character for both factors is the one with higher engagement and also the ones statistically significant. 


